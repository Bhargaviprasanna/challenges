q()
q()
q()
q()
q()
print("hello world")
install.packages("ggforce")
```{r}
print(
'hi
)
print(
'hi
print(
'hi')
library(ggforce)
library(ggplot2)
library(ggforce)
ggplot() +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, angle = 0)) +
coord_fixed()
library(ggplot2)
library(ggforce)
ggplot() +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, angle = 0)) +
coord_fixed() +
theme(legend.position="none",
panel.background = element_rect(fill = 'white'),
panel.grid=element_blank(),
axis.ticks=element_blank(),
axis.title=element_blank(),
axis.text=element_blank())
ggplot() +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, angle = 45)) +
coord_fixed() +
theme(legend.position="none",
panel.background = element_rect(fill = 'white'),
panel.grid=element_blank(),
axis.ticks=element_blank(),
axis.title=element_blank(),
axis.text=element_blank())
ggplot() +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 6, b = 3, angle = -pi / 3, m1 = 3)) +
coord_fixed() +
theme(legend.position="none",
panel.background = element_rect(fill = 'white'),
panel.grid=element_blank(),
axis.ticks=element_blank(),
axis.title=element_blank(),
axis.text=element_blank())
library(ggplot2)
library(ggforce)
ggplot() +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, angle = 45)) +
coord_fixed() +
theme(legend.position="none",
panel.background = element_rect(fill = 'white'),
panel.grid=element_blank(),
axis.ticks=element_blank(),
axis.title=element_blank(),
axis.text=element_blank())
ggplot() +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, angle = 45, color = 'magenta', fill = 'darkgreen')) +
coord_fixed() +
theme(legend.position="none",
panel.background = element_rect(fill = 'white'),
panel.grid=element_blank(),
axis.ticks=element_blank(),
axis.title=element_blank(),
axis.text=element_blank())
ggplot() +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, angle = 45, color = 'magenta')) +
coord_fixed() +
theme(legend.position="none",
panel.background = element_rect(fill = 'white'),
panel.grid=element_blank(),
axis.ticks=element_blank(),
axis.title=element_blank(),
axis.text=element_blank())
ggplot() +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, angle = 45, color = 'magenta', fill = 'blue')) +
coord_fixed() +
theme(legend.position="none",
panel.background = element_rect(fill = 'white'),
panel.grid=element_blank(),
axis.ticks=element_blank(),
axis.title=element_blank(),
axis.text=element_blank())
ggplot() +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, shape = 2, angle = 45, color = 'magenta', fill = 'blue')) +
coord_fixed() +
theme(legend.position="none",
panel.background = element_rect(fill = 'white'),
panel.grid=element_blank(),
axis.ticks=element_blank(),
axis.title=element_blank(),
axis.text=element_blank())
ggplot() +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, size = 12, angle = 45, color = 'magenta', fill = 'blue')) +
coord_fixed() +
theme(legend.position="none",
panel.background = element_rect(fill = 'white'),
panel.grid=element_blank(),
axis.ticks=element_blank(),
axis.title=element_blank(),
axis.text=element_blank())
ggplot() +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, size = 12, angle = 45, color = 'magenta', fill = 'blue', alpha = 0.2)) +
coord_fixed() +
theme(legend.position="none",
panel.background = element_rect(fill = 'white'),
panel.grid=element_blank(),
axis.ticks=element_blank(),
axis.title=element_blank(),
axis.text=element_blank())
ggplot() +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, size = 12, angle = 45, color = 'magenta', fill = 'blue', alpha = 0.2)) +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, size = 12, angle = 90, color = 'magenta', fill = 'blue', alpha = 0.2)) +
coord_fixed() +
theme(legend.position="none",
panel.background = element_rect(fill = 'white'),
panel.grid=element_blank(),
axis.ticks=element_blank(),
axis.title=element_blank(),
axis.text=element_blank())
ggplot() +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, size = 12, angle = 45, color = 'magenta', fill = 'blue', alpha = 0.2)) +
coord_fixed() +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, size = 12, angle = 90, color = 'magenta', fill = 'blue', alpha = 0.2)) +
coord_fixed() +
theme(legend.position="none",
panel.background = element_rect(fill = 'white'),
panel.grid=element_blank(),
axis.ticks=element_blank(),
axis.title=element_blank(),
axis.text=element_blank())
ggplot() +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, size = 12, angle = 45, color = 'magenta', fill = 'blue', alpha = 0.2)) +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, size = 12, angle = 90, color = 'magenta', fill = 'blue', alpha = 0.2)) +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, size = 12, angle = 180, color = 'magenta', fill = 'blue', alpha = 0.2)) +
coord_fixed() +
theme(legend.position="none",
panel.background = element_rect(fill = 'white'),
panel.grid=element_blank(),
axis.ticks=element_blank(),
axis.title=element_blank(),
axis.text=element_blank())
ggplot() +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, size = 12, angle = 45, color = 'magenta', fill = 'blue', alpha = 0.2)) +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, size = 12, angle = 90, color = 'magenta', fill = 'blue', alpha = 0.2)) +
geom_ellipse(aes(x0 = 0, y0 = 0, a = 10, b = 3, size = 12, angle = 135, color = 'magenta', fill = 'blue', alpha = 0.2)) +
coord_fixed() +
theme(legend.position="none",
panel.background = element_rect(fill = 'white'),
panel.grid=element_blank(),
axis.ticks=element_blank(),
axis.title=element_blank(),
axis.text=element_blank())
setwd("C:/Users/jyoth/Downloads/HackerearthChallenge")
dataset_original = read.csv('Reviews.csv')
# Cleaning the texts
# install.packages('tm')
# install.packages('SnowballC')
library(tm)
library(SnowballC)
corpus = VCorpus(VectorSource(dataset_original$original_text))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords())
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, stripWhitespace)
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.999)
dataset = as.data.frame(as.matrix(dtm))
library(caTools)
set.seed(123)
training_set = dataset[1:3235, ]
test_set = dataset[3236:4622, ]
library(randomForest)
classifier = randomForest(x = training_set,
y = dataset_original$sentiment_class,
ntree = 10)
y
dataset_original = read.csv('Reviews.csv')
# Cleaning the texts
# install.packages('tm')
# install.packages('SnowballC')
library(tm)
library(SnowballC)
corpus = VCorpus(VectorSource(dataset_original$original_text))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords())
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, stripWhitespace)
# Creating the Bag of Words model
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.999)
dataset = as.data.frame(as.matrix(dtm))
dataset$sentiment_class = dataset_original$sentiment_class
# # Importing the dataset
# dataset = read.csv('Social_Network_Ads.csv')
# dataset = dataset[3:5]
#
# Encoding the target feature as factor
dataset$sentiment_class = factor(dataset$sentiment_class, levels = c(-1, 0, 1))
library(caTools)
set.seed(123)
training_set = dataset[1:3235, ]
test_set = dataset[3236:4622, ]
library(randomForest)
set.seed(123)
classifier = randomForest(x = training_set[-1512],
y = training_set$sentiment_class,
ntree = 10) #25
y_pred = predict(classifier, newdata = test_set[-1512])
View(test_set)
View(test_set)
test_set = dataset[3236:4622, ]
y_pred = predict(classifier, newdata = test_set[-1512])
y_pred = predict(classifier, newdata = training_set[-1512])
cm = table(training_set[, 1513], y_pred)
cm
y_pred_test = predict(classifier, newdata = test_set[-1512])
View(test_set)
y_pred_test = predict(classifier, newdata = test_set[, -1])
View(training_set)
y_pred_test = predict(classifier, newdata = test_set[1512])
y_pred_test = predict(classifier, newdata = test_set[1513])
y_pred_test = predict(classifier, newdata = test_set[1511])
# Importing the dataset
dataset_original = read.csv('Reviews.csv')
# Cleaning the texts
# install.packages('tm')
# install.packages('SnowballC')
library(tm)
library(SnowballC)
corpus = VCorpus(VectorSource(dataset_original$original_text))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords())
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, stripWhitespace)
# Creating the Bag of Words model
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.999)
dataset = as.data.frame(as.matrix(dtm))
# dataset$sentiment_class = dataset_original$sentiment_class
# # Importing the dataset
# dataset = read.csv('Social_Network_Ads.csv')
# dataset = dataset[3:5]
#
# Encoding the target feature as factor
dataset$sentiment_class = factor(dataset$sentiment_class, levels = c(-1, 0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
training_set = dataset[1:3235, ]
test_set = dataset[3236:4622, ]
# f <- list(1, -1, 0)
library(randomForest)
set.seed(123)
classifier = randomForest(x = training_set,
y = dataset_original$sentiment_class,
ntree = 10) #25
test_set[1513]
test_set[1512]
dataset$sentiment_class = dataset_original$sentiment_class
dataset$sentiment_class = factor(dataset$sentiment_class, levels = c(-1, 0, 1))
test_set['sentiment_class'] = 0
library(caTools)
set.seed(123)
training_set = dataset[1:3235, ]
test_set = dataset[3236:4622, ]
test_set['sentiment_class'] = 0
test_set[1513]
library(randomForest)
set.seed(123)
classifier = randomForest(x = training_set[-1512],
y = dataset_original$sentiment_class,
ntree = 10) #25
set.seed(123)
classifier = randomForest(x = training_set[-1512],
y = training_set$sentiment_class,
ntree = 10) #25
y_pred = predict(classifier, newdata = training_set[-1512])
cm = table(training_set[, 1513], y_pred)
cm
y_pred_test = predict(classifier, newdata = test_set[-1512])
dataset_original = read.csv('Reviews.csv')
View(dataset_original)
View(dataset_original)
library(tm)
library(SnowballC)
corpus = VCorpus(VectorSource(dataset_original$original_text))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords())
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, stripWhitespace)
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.999)
dataset = as.data.frame(as.matrix(dtm))
dataset$sentiment_class = dataset_original$sentiment_class
dataset$sentiment_class = factor(dataset$sentiment_class, levels = c(-1, 0, 1))
library(caTools)
set.seed(123)
# training_set = dataset[1:3235, ]
# test_set = dataset[3236:4622, ]
# test_set['sentiment_class'] = 0
split = sample.split(dataset$sentiment_class, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
split = sample.split(dataset$sentiment_class, SplitRatio = 0.65)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
training_set = dataset[1:3235, ]
test_set = dataset[3236:4622, ]
library(randomForest)
set.seed(123)
classifier = randomForest(x = training_set[-1512],
y = training_set$sentiment_class,
ntree = 10) #25
y_pred = predict(classifier, newdata = training_set[-1512])
cm = table(training_set[, 1513], y_pred)
y_pred_test = predict(classifier, newdata = test_set[-1512])
test_set[-1512][0]
test_set[-1512]
training_set[-1512]
summary(classifier)
cm
len(test_set)
test_set[1513]
y_pred_test = predict(classifier, newdata = test_set[-1512])
y_pred_test = predict(classifier$learner.model, newdata = test_set[-1512])
test_set[1513] <- 0
test_set[1513]
y_pred_test = predict(classifier$learner.model, newdata = test_set[-1512])
y_pred_test = predict(classifier, newdata = test_set[-1512])
train_data = read.csv('dataset\\train.csv')
test_data = read.csv('dataset\\test.csv')
train_data = read.csv('dataset\\train.csv')
test_data = read.csv('dataset\\test.csv')
View(test_data)
View(train_data)
train_data = train_data[,2,6]
train_data
train_data = train_data[,2]
train_data = read.csv('dataset\\train.csv')
train_d = train_data[,2]
test_d = test_data[,2]
test_d[1][1]
dataset = list(train_d,test_d)
View(dataset)
View(dataset)
append(train_d,test_d)
library(tm)
library(SnowballC)
corpus = VCorpus(VectorSource(train_d))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords())
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, stripWhitespace)
train_data = read.csv('dataset\\train.csv')
train_d = train_data$original_text
test_data = read.csv('dataset\\test.csv')
test_d = test_data$original_text
append(train_d,test_d) # train_d contains all the original_text
train_data = read.csv('dataset\\train.csv')
train_d = train_data$original_text
test_data = read.csv('dataset\\test.csv')
test_d = test_data$original_text
dataset = read.csv('Reviews.csv')
summary(dataset$sentiment_class)
dataset_original = read.csv('Reviews.csv')
# Cleaning the texts
# install.packages('tm')
# install.packages('SnowballC')
library(tm)
library(SnowballC)
corpus = VCorpus(VectorSource(dataset_original$original_text))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords())
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, stripWhitespace)
# Creating the Bag of Words model
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.999)
dataset = as.data.frame(as.matrix(dtm))
dataset$sentiment_class = dataset_original$sentiment_class
dataset$sentiment_class = factor(dataset$sentiment_class, levels = c(-1, 0, 1))
library(caTools)
set.seed(123)
training_set = dataset[1:3235, ]
test_set = dataset[3236:4622, ]
summary(test_set)
summary(train_set$sentiment_class)
summary(training_set$sentiment_class)
summary(test_set$sentiment_class)
test_set$sentiment_class = 0
summary(test_set$sentiment_class)
test_set$sentiment_class <- 0
summary(test_set$sentiment_class)
summary(training_set$sentiment_class)
test_set = dataset[3236:4622, ]
summary(test_set$sentiment_class)
dataset$sentiment_class = ifelse(is.na(dataset$sentiment_class),
ave(dataset$sentiment_class, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$sentiment_class)
dataset$sentiment_class[is.na(dataset$sentiment_class)] <- 0
summary(dataset$sentiment_class)
summary(dataset)
View(dataset)
dataset_original = read.csv('Reviews.csv')
library(tm)
library(SnowballC)
corpus = VCorpus(VectorSource(dataset_original$original_text))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords())
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, stripWhitespace)
# Creating the Bag of Words model
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.999)
dataset = as.data.frame(as.matrix(dtm))
dataset$sentiment_class = dataset_original$sentiment_class
summary(dataset$sentiment_class)
dataset$sentiment_class[is.na(dataset$sentiment_class)] <- 0
summary(dataset$sentiment_class)
# Encoding the target feature as factor
dataset$sentiment_class = factor(dataset$sentiment_class, levels = c(-1, 0, 1))
library(caTools)
set.seed(123)
training_set = dataset[1:3235, ]
test_set = dataset[3236:4622, ]
summary(test_set$sentiment_class)
library(randomForest)
set.seed(123)
classifier = randomForest(x = training_set[-1512],
y = training_set$sentiment_class,
ntree = 10) #25
y_pred = predict(classifier, newdata = training_set[-1512])
cm = table(training_set[, 1513], y_pred)
cm
y_pred_test = predict(classifier, newdata = test_set[-1512])
install.packages("MLmetrics")
library(MLmetrics)
F1_Score(training_set[, 1513], y_pred)
x = read.csv('test.csv')
x = read.csv('dataset\\test.csv')
df <- data.frame(x$id,y_pred_test)
View(df)
summary(y_pred_test)
summary(test_set$sentiment_class)
summary(training_set$sentiment_class)
df
df <- data.frame('id' = x$id,'sentiment_class' = y_pred_test)
summary(df)
write.csv(df,'Submission_file_R.csv')
View(df)
df2 = read.csv('submission_file2.csv')
View(df2)
write.csv(df,'Submission_file_R.csv',row.names = FALSE)
class(df$sentiment_class)
class(df$id)
df$sentiment_class <- sapply(df$sentiment_class, as.numeric)
class(df$sentiment_class)
write.csv(df,'Submission_file_R.csv',row.names = FALSE)
df <- data.frame('id' = x$id,'sentiment_class' = y_pred_test)
View(df)
df <- data.frame(id = x$id,sentiment_class = y_pred_test)
write.csv(df,'Submission_file_R.csv',row.names = FALSE)
write.csv(df,'Submission_file_R.csv',row.names = FALSE, col.names = FALSE)
class(df)
class(df$id)
class(df$sentiment_class)
df[1.24416497296969e+18]
df[,1.24416497296969e+18]
View(x)
