{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X1kiO9kACE6s"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QG7sxmoCIvN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTtCiq8SWKFz"
   },
   "source": [
    "## Combine both train and test data to form sparse matrix of 'original_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZqCXpI7DU3jL"
   },
   "outputs": [],
   "source": [
    "a = pd.read_csv('train.csv')\n",
    "train_row_count = len(a.index)\n",
    "b = pd.read_csv('test.csv')\n",
    "test_row_count = len(b.index)\n",
    "merged = pd.concat([a,b], axis=0)\n",
    "merged.to_csv('Reviews.csv', index=False)\n",
    "# print(train_row_count, test_row_count)\n",
    "# 3235+1387"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wTfaCIzdCLPA"
   },
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UCK6vQ5QCQJe"
   },
   "outputs": [],
   "source": [
    "#Merged test and train set as Reviews.csv\n",
    "dataset = pd.read_csv('Reviews.csv')\n",
    "total_count = train_row_count + test_row_count\n",
    "# print(dataset.head(5)) \n",
    "# 0 for Neutral , 1 for Positive, -1 for Negative\n",
    "dataset = dataset.loc[:, ['original_text','sentiment_class']].values\n",
    "# dataset[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "60rnpcQICtJk"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qekztq71CixT"
   },
   "source": [
    "## Cleaning the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8u_yXh9dCmEE",
    "outputId": "70c5a47c-5671-4db1-c3a4-97cc2de17b16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus = []\n",
    "for i in range(0, 4622):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset[i][0])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CLqmAkANCp1-"
   },
   "source": [
    "## Creating the Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qroF7XcSCvY3"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 4000)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset[:, -1]\n",
    "y = y.astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DH_VjgPzC2cd"
   },
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQXYM5VzDDDI"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = X[:train_row_count]\n",
    "X_test = X[train_row_count:]\n",
    "y_train = y[:train_row_count]\n",
    "y_test = y[train_row_count:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JsMohmN0bRfN"
   },
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "NkX6WqVGPkKP",
    "outputId": "8e3d7e8e-57f0-413b-da25-441549a2b6ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JaRM7zXDWUy"
   },
   "source": [
    "## Predicting the Train set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Iif0CVhFDaMp",
    "outputId": "067d0bbd-5db4-4457-f568-b7040887c838"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0., -1., ...,  0.,  0., -1.])"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_train)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xoMltea5Dir1"
   },
   "source": [
    "## Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "B7I8EvC9QUET",
    "outputId": "6ea1b658-7a44-4b50-ed36-ab2305afcf4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 749   20    0]\n",
      " [   4 1697    0]\n",
      " [   6   51  708]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' for n =100 [[ 764    5    0]\\n [   0 1701    0]\\n [   2    2  761]]\\n # n = 10 [[ 749   20    0]\\n [   4 1697    0]\\n [   6   51  708]]'"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print(cm)\n",
    "\"\"\" for n =100 [[ 764    5    0]\n",
    " [   0 1701    0]\n",
    " [   2    2  761]]\n",
    " # n = 10 [[ 749   20    0]\n",
    " [   4 1697    0]\n",
    " [   6   51  708]]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jg8JiiMnce8n"
   },
   "source": [
    "## Score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IvTZBZdWcd95",
    "outputId": "e210115e-3ef0-4e71-9c78-0974f1f5250c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.48139886434113"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "score = 100*f1_score(y_train, y_pred, average='weighted')\n",
    "score\n",
    "#97.48139886434113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "62ZUN5C8bf_i"
   },
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7CaeUhm0bpAU"
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W5bPr_xxcAgM"
   },
   "source": [
    "## Final Submission file of id, sentiment_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PUIWQlADSAqx"
   },
   "outputs": [],
   "source": [
    "p = pd.read_csv('Reviews.csv')\n",
    "d = p.iloc[3235:, 0].values\n",
    "dict = {'id': d, 'sentiment_class': y_pred}\n",
    "df = pd.DataFrame(dict)\n",
    "df.to_csv('submission_file2.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HackerEarthMothersDayChallenge.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
